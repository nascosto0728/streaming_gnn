# Data paths
data_path: './datasets/record_movielens.parquet'
meta_path: './datasets/content_movielens.parquet'

# Experiment settings
dir_name: 'Meta_Refactored_Experiment'
shuffle: false
restored_ckpt_mode: 'last'

# Training loop settings
learning_rates: [0.001]
num_periods: 14
train_start_period: 0
test_start_period: 8
max_epochs: 10         # 每個 period 最多跑 100 個 epoch
validation_split: 0.2   # 從「當前 period」切 20% 出來當驗證集
patience: 1            # 驗證集損失 (val_loss) 連續 10 次沒進步就停止

debug_sample: 0

evaluation:
  sampling_size: 99
  Ks: [5, 10, 20, 50]

item_vec_path: './vectors/item_vectors_kge.npy'
cate_vec_path: './vectors/cate_vectors.npy'

continual_learning:
  replay_enabled: false             # 設為 true 來啟用經驗回放
  replay_buffer_size: 500000        # 緩衝區最大容量 (例如 5 萬筆)
  replay_add_size_per_period: 50000   # 每期結束後，從當期資料隨機存 50000 筆
  replay_sample_size_per_period: 30000 # 每期訓練時，從緩衝區取出 30000 筆

distillation:
  enabled: false   
  weight: 100.5            # 蒸餾權重 (lambda)，可以試試 0.1, 0.5, 1.0

# 選項: 'hybrid'  'mlp'  'lightgcn_only'  
#'sr_gnn' 'sr_gnn_mlp' 
#'pure_sasrec' 'sasrec_mlp' 'causal_sasrec_mlp' 'context_sasrec_mlp' 'dual_prompt_sasrec' ' hyper_lora_sasrec'
model_type: 'hyper_lora_sasrec'
# Model Hyperparameters
model:
  batch_size: 1024
  text_embed_dim: 384
  user_embed_dim: 128 
  item_embed_dim: 128
  cate_embed_dim: 64
  lora_r: 64 # LoRA rank for hyper_lora_sasrec
